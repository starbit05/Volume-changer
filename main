import cv2  # Βιβλιοθήκη για χρήση κάμερας
import trackingHands as htm  # Scriptaki για την ανιχνευση χεριών

# για ελεγχο ήχου
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
from ctypes import cast, POINTER  # για χρήση δεδομένων τύπου C
from comtypes import CLSCTX_ALL
# Για τον υπολογισμό FPS θα διαιρούμε την διαφορά χρόνου ανάμεσα σε κάθε
# frame από το 1  (1/(currentTime-previousTime))
import time
import math
import numpy as np

wCam, hCam = 640, 480  # Μέγεθος παραθύρου κάμερας

cap = cv2.VideoCapture(0)  # Ορισμός κάμερας

# Ορισμός του μεγέθους
cap.set(3, wCam)
cap.set(4, hCam)
pTime = 0  # previousTime

detector = htm.handDetector(detectionCon=0.7)  # δημιουργία αντικειμένου handDetector

devices = AudioUtilities.GetSpeakers()
interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)  # αλλαγή έντασης
volume = cast(interface, POINTER(IAudioEndpointVolume))  # pointer volume για αλλαγή έντασης

# μεταβητές για την ένταση
volRange = volume.GetVolumeRange()
minVol = volRange[0]
maxVol = volRange[1]
vol = 0  # η ενταση
volBar = 400  # η μπάρα που θα ανεβωκατεβαίνει στην οθόνη
volPer = 0  # Το ποσοστό που θα εμφανίζεται στην οθόνη

while True:

    # cap.read() επιστρέφει εάν ήταν επυτχιά η καταγραφή του frame (success = True/False)
    # και την εικόνα (img)
    success, img = cap.read()

    img = detector.findHands(img)  # Βρες τα χερια στην εικόνα
    lmList = detector.findPosition(img, draw=False)  # Κράτα την τοποθεσία τους

    # Εάν η λίστα δεν είναι κενή κρατάμε τις συντεταγμένες των δάχτυλων που θέλουμε
    # καθώς και τα κέντρα των 2 σημείων
    if lmList != ([], []):
        x1, y1 = lmList[0][4][1], lmList[0][4][2]  # το 4 είναι ο αντίχειρας
        x2, y2 = lmList[0][20][1], lmList[0][20][2]  # το 20 είναι το μικρό δάχτυλο
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2  # τα κέντρα τους

        # παράμετροι: (εικόνα, κέντρο, διάμετρος, χρώμα, thickness)
        cv2.circle(img, (x1, y1), 15, (255, 0, 255), cv2.FILLED)  # Κύκλος στο π΄ρωτο δάχτυλο
        cv2.circle(img, (x2, y2), 15, (255, 0, 255), cv2.FILLED)  # κύκλος στο δεύτερο δάχτυλο

        # παράμετροι: (εικόνα, πρώτο σημείο, δεύτερο σημείο, χρώμα, thickness)
        cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 3)  # γραμμή μεταξύ των 2 σημείων
        cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED)  # κύκλος στο κέντρο

        length = math.hypot(x2 - x1, y2 - y1)  # υπολογισμός απόστασης σημείων δαχτύλων

        # Υπολογισμός την έντασης, της μπάρας και του ποσοστού του ήχου σύμφωνα
        # με το length και τος περιορισμό των τιμών που πρέπει να έχουν
        vol = np.interp(length, [50, 300], [minVol, maxVol])
        volBar = np.interp(length, [50, 300], [400, 150])
        volPer = np.interp(length, [50, 300], [0, 100])

        # Ορισμός έντασης
        volume.SetMasterVolumeLevel(vol, None)
        print("length: " + str(length) + ", vol: " + str(vol))

        # αλλαγή χρώματος στο κέντρο
        if length < 50:
            cv2.circle(img, (cx, cy), 15, (0, 255, 0), cv2.FILLED)

    cTime = time.time()  # currentTime
    fps = 1 / (cTime - pTime)  # υπολογισμός FPS
    pTime = cTime  # αλλαγή του previousTime

    # putText τοποθετεί κείμενο στην εικόνα με παραμέτρους:
    # (η εικόνα, το κείμενο, θέση (x,y), γραμματοσειρά, μεγεθος, RGB χρώμα, thickness)
    cv2.putText(img, "FPS: " + str(int(fps)), (40, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 3)

    # Εμφανίζει το frame σε παράθυρο με όνομα Gesture Volume Control
    cv2.imshow("Gesture Volume Control", img)

    # κρατάμε και ελέγχουμε ποιο πλήκτρο πάτησε ο χρήσης
    k = cv2.waitKey(1)
    if k % 256 == 27:
        # ESC pressed
        print("Escape hit, closing...")
        break

# απελευθερώνουμε τους πόρους και κλείνουμε τα παράθυρα
cap.release()
cv2.destroyAllWindows()
